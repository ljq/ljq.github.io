<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta><title>基于Go语言实现Transformer模型（包含训练、保存、加载和交互式文本生成功能） - Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节.</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节."><meta name="msapplication-TileImage" content="/img/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节."><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="基于Go语言实现Transformer模型，包含训练、保存、加载和交互式文本生成功能，纯CPU运行，仅依赖标准库和gonum，帮助理解大模型的运行本质原理："><meta property="og:type" content="blog"><meta property="og:title" content="基于Go语言实现Transformer模型（包含训练、保存、加载和交互式文本生成功能）"><meta property="og:url" content="https://www.wdft.com/3bdefda4.html"><meta property="og:site_name" content="Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节."><meta property="og:description" content="基于Go语言实现Transformer模型，包含训练、保存、加载和交互式文本生成功能，纯CPU运行，仅依赖标准库和gonum，帮助理解大模型的运行本质原理："><meta property="og:locale" content="en_US"><meta property="og:image" content="https://www.wdft.com/assets/images/ai-logo.png"><meta property="article:published_time" content="2026-01-18T17:17:34.000Z"><meta property="article:modified_time" content="2026-01-30T19:58:18.770Z"><meta property="article:author" content="Jaco Liu"><meta property="article:tag" content="AI"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Go"><meta property="article:tag" content="Go-LLM"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/assets/images/ai-logo.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.wdft.com/3bdefda4.html"},"headline":"基于Go语言实现Transformer模型（包含训练、保存、加载和交互式文本生成功能）","image":["https://www.wdft.com/assets/images/ai-logo.png"],"datePublished":"2026-01-18T17:17:34.000Z","dateModified":"2026-01-30T19:58:18.770Z","author":{"@type":"Person","name":"Jaco Liu"},"publisher":{"@type":"Organization","name":"Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节.","logo":{"@type":"ImageObject","url":"https://www.wdft.com/img/logo.svg"}},"description":"基于Go语言实现Transformer模型，包含训练、保存、加载和交互式文本生成功能，纯CPU运行，仅依赖标准库和gonum，帮助理解大模型的运行本质原理："}</script><link rel="canonical" href="https://www.wdft.com/3bdefda4.html"><link rel="alternate" href="/atom.xml" title="Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节." type="application/atom+xml"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.15.2/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><script>!function(){var e=document.createElement("script"),t=(e.src="//hm.baidu.com/hm.js?45914c5ebb523a9ed07ab35e4dc81374",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><meta name="msvalidate.01" content="ad0df3c8d20f49daaeb5baa3c9dbfe75"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8952360410310192" crossorigin="anonymous"></script><script>!function(){function e(){if(location.hash){Array.from(document.querySelectorAll(".tab-content")).forEach(e=>{e.classList.add("is-hidden")}),Array.from(document.querySelectorAll(".tabs li")).forEach(e=>{e.classList.remove("is-active")});const e=document.querySelector(location.hash),t=(e&&e.classList.remove("is-hidden"),document.querySelector(`a[href="${location.hash}"]`));t&&t.parentElement.classList.add("is-active")}}e(),window.addEventListener("hashchange",e,!1)}()</script><meta name="generator" content="Hexo 6.1.0"></head><body class="is-2-column"><img src="/img/avatar.jpeg" width="0" height="0"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节." height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/musics">Musics</a><a class="navbar-item" href="/videos">Videos</a><a class="navbar-item" href="/galleries">Galleries</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item dark-mode-btn" title="Light|Dark" rel="noopener" onclick="switchDarkMode()">    <i class="fas fa-lightbulb">  </i></a><a class="navbar-item" target="_blank" rel="noopener" title="Musics" href="/musics"><i class="fas fa-music"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Videos" href="/videos"><i class="fas fa-video"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="WeChat Account (labsec)" href="/assets/images/about/ljq-qrcode.jpeg"><i class="fab fa-weixin"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Jaco Liu GitHub" href="https://github.com/ljq"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/assets/images/ai-logo.png" alt="基于Go语言实现Transformer模型（包含训练、保存、加载和交互式文本生成功能）"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time datetime="2026-01-18T17:17:34.000Z" title="1/19/2026, 1:17:34 AM">2026-01-19</time></span><span class="level-item">Updated&nbsp;<time datetime="2026-01-30T19:58:18.770Z" title="1/31/2026, 3:58:18 AM">2026-01-31</time></span><span class="level-item"> Jaco Liu </span><span class="level-item"><a class="link-muted" href="/categories/AI/">AI</a><span> / </span><a class="link-muted" href="/categories/AI/LLM/">LLM</a></span><span class="level-item">an hour read (About 7510 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">基于Go语言实现Transformer模型（包含训练、保存、加载和交互式文本生成功能）</h1><div class="content"><p>基于Go语言实现Transformer模型，包含训练、保存、加载和交互式文本生成功能，纯CPU运行，仅依赖标准库和gonum，帮助理解大模型的运行本质原理：</p><span id="more"></span><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;encoding/gob&quot;</span></span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;log&quot;</span></span><br><span class="line">	<span class="string">&quot;math&quot;</span></span><br><span class="line">	<span class="string">&quot;math/rand&quot;</span></span><br><span class="line">	<span class="string">&quot;os&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line"></span><br><span class="line">	<span class="string">&quot;gonum.org/v1/gonum/mat&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 基础工具函数 ==========</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成指定范围内的随机浮点数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">randFloat64</span><span class="params">(min, max <span class="type">float64</span>)</span></span> <span class="type">float64</span> &#123;</span><br><span class="line">	<span class="keyword">return</span> min + rand.Float64()*(max-min)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Softmax函数：将向量转换为概率分布</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">softmax</span><span class="params">(x *mat.VecDense)</span></span> *mat.VecDense &#123;</span><br><span class="line">	n := x.Len()</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 数值稳定性：减去最大值防止exp溢出</span></span><br><span class="line">	maxVal := x.AtVec(<span class="number">0</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">1</span>; i &lt; n; i++ &#123;</span><br><span class="line">		<span class="keyword">if</span> x.AtVec(i) &gt; maxVal &#123;</span><br><span class="line">			maxVal = x.AtVec(i)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	result := mat.NewVecDense(n, <span class="literal">nil</span>)</span><br><span class="line">	sum := <span class="number">0.0</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">		expVal := math.Exp(x.AtVec(i) - maxVal)</span><br><span class="line">		result.SetVec(i, expVal)</span><br><span class="line">		sum += expVal</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 归一化</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">		result.SetVec(i, result.AtVec(i)/sum)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Layer Normalization：对向量进行归一化</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">layerNorm</span><span class="params">(x *mat.VecDense, eps <span class="type">float64</span>)</span></span> *mat.VecDense &#123;</span><br><span class="line">	n := x.Len()</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 计算均值</span></span><br><span class="line">	mean := <span class="number">0.0</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">		mean += x.AtVec(i)</span><br><span class="line">	&#125;</span><br><span class="line">	mean /= <span class="type">float64</span>(n)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 计算方差</span></span><br><span class="line">	variance := <span class="number">0.0</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">		diff := x.AtVec(i) - mean</span><br><span class="line">		variance += diff * diff</span><br><span class="line">	&#125;</span><br><span class="line">	variance /= <span class="type">float64</span>(n)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 归一化：(x - mean) / sqrt(variance + eps)</span></span><br><span class="line">	std := math.Sqrt(variance + eps)</span><br><span class="line">	result := mat.NewVecDense(n, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">		result.SetVec(i, (x.AtVec(i)-mean)/std)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 位置编码：为序列添加位置信息 ==========</span></span><br><span class="line"><span class="keyword">type</span> PositionalEncoding <span class="keyword">struct</span> &#123;</span><br><span class="line">	DModel <span class="type">int</span>          <span class="comment">// 模型维度</span></span><br><span class="line">	MaxLen <span class="type">int</span>          <span class="comment">// 最大序列长度</span></span><br><span class="line">	Cache  *mat.Dense   <span class="comment">// 预计算的位置编码缓存</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建位置编码层</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewPositionalEncoding</span><span class="params">(dModel, maxLen <span class="type">int</span>)</span></span> *PositionalEncoding &#123;</span><br><span class="line">	pe := mat.NewDense(maxLen, dModel, <span class="literal">nil</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 根据Transformer论文公式计算位置编码</span></span><br><span class="line">	<span class="comment">// PE(pos, 2i) = sin(pos / 10000^(2i/d_model))</span></span><br><span class="line">	<span class="comment">// PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))</span></span><br><span class="line">	<span class="keyword">for</span> pos := <span class="number">0</span>; pos &lt; maxLen; pos++ &#123;</span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; dModel; i += <span class="number">2</span> &#123;</span><br><span class="line">			divTerm := math.Pow(<span class="number">10000</span>, <span class="type">float64</span>(i)/<span class="type">float64</span>(dModel))</span><br><span class="line">			pe.Set(pos, i, math.Sin(<span class="type">float64</span>(pos)/divTerm))</span><br><span class="line">			<span class="keyword">if</span> i+<span class="number">1</span> &lt; dModel &#123;</span><br><span class="line">				pe.Set(pos, i+<span class="number">1</span>, math.Cos(<span class="type">float64</span>(pos)/divTerm))</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &amp;PositionalEncoding&#123;dModel, maxLen, pe&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前向传播：将位置编码添加到输入嵌入</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(pe *PositionalEncoding)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">	result := mat.NewDense(x.RawMatrix().Rows, x.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	result.Copy(x)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 逐位置添加编码</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; x.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; pe.DModel; j++ &#123;</span><br><span class="line">			result.Set(i, j, result.At(i, j)+pe.Cache.At(i, j))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 多头自注意力机制（简化为单头） ==========</span></span><br><span class="line"><span class="keyword">type</span> SelfAttention <span class="keyword">struct</span> &#123;</span><br><span class="line">	DModel <span class="type">int</span>          <span class="comment">// 模型维度</span></span><br><span class="line">	Wq     *mat.Dense   <span class="comment">// Query权重矩阵</span></span><br><span class="line">	Wk     *mat.Dense   <span class="comment">// Key权重矩阵</span></span><br><span class="line">	Wv     *mat.Dense   <span class="comment">// Value权重矩阵</span></span><br><span class="line">	Wo     *mat.Dense   <span class="comment">// 输出投影矩阵</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建自注意力层</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewSelfAttention</span><span class="params">(dModel <span class="type">int</span>)</span></span> *SelfAttention &#123;</span><br><span class="line">	scale := math.Sqrt(<span class="type">float64</span>(dModel)) <span class="comment">// Xavier初始化缩放因子</span></span><br><span class="line">	<span class="keyword">return</span> &amp;SelfAttention&#123;</span><br><span class="line">		DModel: dModel,</span><br><span class="line">		Wq:     mat.NewDense(dModel, dModel, randWeights(dModel*dModel, scale)),</span><br><span class="line">		Wk:     mat.NewDense(dModel, dModel, randWeights(dModel*dModel, scale)),</span><br><span class="line">		Wv:     mat.NewDense(dModel, dModel, randWeights(dModel*dModel, scale)),</span><br><span class="line">		Wo:     mat.NewDense(dModel, dModel, randWeights(dModel*dModel, scale)),</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成随机权重（Xavier初始化）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">randWeights</span><span class="params">(size <span class="type">int</span>, scale <span class="type">float64</span>)</span></span> []<span class="type">float64</span> &#123;</span><br><span class="line">	w := <span class="built_in">make</span>([]<span class="type">float64</span>, size)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="keyword">range</span> w &#123;</span><br><span class="line">		w[i] = randFloat64(<span class="number">-1.0</span>/scale, <span class="number">1.0</span>/scale)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> w</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前向传播：计算自注意力</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sa *SelfAttention)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">	<span class="comment">// 1. 计算Q, K, V: X * W</span></span><br><span class="line">	q := mat.NewDense(x.RawMatrix().Rows, sa.DModel, <span class="literal">nil</span>)</span><br><span class="line">	q.Mul(x, sa.Wq)</span><br><span class="line">	</span><br><span class="line">	k := mat.NewDense(x.RawMatrix().Rows, sa.DModel, <span class="literal">nil</span>)</span><br><span class="line">	k.Mul(x, sa.Wk)</span><br><span class="line">	</span><br><span class="line">	v := mat.NewDense(x.RawMatrix().Rows, sa.DModel, <span class="literal">nil</span>)</span><br><span class="line">	v.Mul(x, sa.Wv)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 2. 计算注意力分数: Q * K^T / sqrt(d_k)</span></span><br><span class="line">	kT := mat.NewDense(sa.DModel, k.RawMatrix().Rows, <span class="literal">nil</span>)</span><br><span class="line">	kT.TCopy(k) <span class="comment">// 转置K</span></span><br><span class="line">	</span><br><span class="line">	scores := mat.NewDense(q.RawMatrix().Rows, kT.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	scores.Mul(q, kT)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 缩放点积（防止梯度消失）</span></span><br><span class="line">	scale := math.Sqrt(<span class="type">float64</span>(sa.DModel))</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; scores.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; scores.RawMatrix().Cols; j++ &#123;</span><br><span class="line">			scores.Set(i, j, scores.At(i, j)/scale)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 3. 对每行应用Softmax得到注意力权重</span></span><br><span class="line">	attn := mat.NewDense(scores.RawMatrix().Rows, scores.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; scores.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		row := mat.NewVecDense(scores.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; scores.RawMatrix().Cols; j++ &#123;</span><br><span class="line">			row.SetVec(j, scores.At(i, j))</span><br><span class="line">		&#125;</span><br><span class="line">		softmaxRow := softmax(row)</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; scores.RawMatrix().Cols; j++ &#123;</span><br><span class="line">			attn.Set(i, j, softmaxRow.AtVec(j))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 4. 加权求和: attn * V</span></span><br><span class="line">	output := mat.NewDense(attn.RawMatrix().Rows, v.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	output.Mul(attn, v)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 5. 输出投影: output * Wo</span></span><br><span class="line">	result := mat.NewDense(output.RawMatrix().Rows, sa.DModel, <span class="literal">nil</span>)</span><br><span class="line">	result.Mul(output, sa.Wo)</span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 前馈神经网络 ==========</span></span><br><span class="line"><span class="keyword">type</span> FeedForward <span class="keyword">struct</span> &#123;</span><br><span class="line">	W1 *mat.Dense    <span class="comment">// 第一层权重</span></span><br><span class="line">	B1 *mat.VecDense  <span class="comment">// 第一层偏置</span></span><br><span class="line">	W2 *mat.Dense    <span class="comment">// 第二层权重</span></span><br><span class="line">	B2 *mat.VecDense  <span class="comment">// 第二层偏置</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建前馈网络（两层MLP）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewFeedForward</span><span class="params">(dModel, dFF <span class="type">int</span>)</span></span> *FeedForward &#123;</span><br><span class="line">	<span class="comment">// Xavier初始化缩放因子</span></span><br><span class="line">	scale1 := math.Sqrt(<span class="number">2.0</span> / <span class="type">float64</span>(dModel))</span><br><span class="line">	scale2 := math.Sqrt(<span class="number">2.0</span> / <span class="type">float64</span>(dFF))</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> &amp;FeedForward&#123;</span><br><span class="line">		W1: mat.NewDense(dModel, dFF, randWeights(dModel*dFF, scale1)),</span><br><span class="line">		B1: mat.NewVecDense(dFF, <span class="literal">nil</span>),</span><br><span class="line">		W2: mat.NewDense(dFF, dModel, randWeights(dFF*dModel, scale2)),</span><br><span class="line">		B2: mat.NewVecDense(dModel, <span class="literal">nil</span>),</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前向传播：ReLU激活的两层网络</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ff *FeedForward)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">	<span class="comment">// 第一层: ReLU(x * W1 + B1)</span></span><br><span class="line">	hidden := mat.NewDense(x.RawMatrix().Rows, ff.W1.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	hidden.Mul(x, ff.W1)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 添加偏置并应用ReLU</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; hidden.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; hidden.RawMatrix().Cols; j++ &#123;</span><br><span class="line">			val := hidden.At(i, j) + ff.B1.AtVec(j)</span><br><span class="line">			<span class="keyword">if</span> val &lt; <span class="number">0</span> &#123;</span><br><span class="line">				val = <span class="number">0</span> <span class="comment">// ReLU激活</span></span><br><span class="line">			&#125;</span><br><span class="line">			hidden.Set(i, j, val)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 第二层: hidden * W2 + B2（无激活函数）</span></span><br><span class="line">	output := mat.NewDense(hidden.RawMatrix().Rows, ff.W2.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	output.Mul(hidden, ff.W2)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; output.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; output.RawMatrix().Cols; j++ &#123;</span><br><span class="line">			output.Set(i, j, output.At(i, j)+ff.B2.AtVec(j))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> output</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== Transformer编码块 ==========</span></span><br><span class="line"><span class="keyword">type</span> TransformerBlock <span class="keyword">struct</span> &#123;</span><br><span class="line">	DModel        <span class="type">int</span>             <span class="comment">// 模型维度</span></span><br><span class="line">	SelfAttention *SelfAttention  <span class="comment">// 自注意力层</span></span><br><span class="line">	FF            *FeedForward    <span class="comment">// 前馈网络</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建Transformer块</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewTransformerBlock</span><span class="params">(dModel, dFF <span class="type">int</span>)</span></span> *TransformerBlock &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;TransformerBlock&#123;</span><br><span class="line">		DModel:        dModel,</span><br><span class="line">		SelfAttention: NewSelfAttention(dModel),</span><br><span class="line">		FF:            NewFeedForward(dModel, dFF),</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前向传播：带残差连接和层归一化</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tb *TransformerBlock)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">	<span class="comment">// 1. 自注意力 + 残差连接</span></span><br><span class="line">	attnOut := tb.SelfAttention.Forward(x)</span><br><span class="line">	residual1 := mat.NewDense(x.RawMatrix().Rows, x.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	residual1.Add(x, attnOut) <span class="comment">// 残差连接: x + attn(x)</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 2. 层归一化</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; residual1.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		row := mat.NewVecDense(tb.DModel, <span class="literal">nil</span>)</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; tb.DModel; j++ &#123;</span><br><span class="line">			row.SetVec(j, residual1.At(i, j))</span><br><span class="line">		&#125;</span><br><span class="line">		ln := layerNorm(row, <span class="number">1e-5</span>)</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; tb.DModel; j++ &#123;</span><br><span class="line">			residual1.Set(i, j, ln.AtVec(j))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 3. 前馈网络 + 残差连接</span></span><br><span class="line">	ffOut := tb.FF.Forward(residual1)</span><br><span class="line">	residual2 := mat.NewDense(residual1.RawMatrix().Rows, residual1.RawMatrix().Cols, <span class="literal">nil</span>)</span><br><span class="line">	residual2.Add(residual1, ffOut) <span class="comment">// 残差连接: x + ff(x)</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 4. 层归一化</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; residual2.RawMatrix().Rows; i++ &#123;</span><br><span class="line">		row := mat.NewVecDense(tb.DModel, <span class="literal">nil</span>)</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; tb.DModel; j++ &#123;</span><br><span class="line">			row.SetVec(j, residual2.At(i, j))</span><br><span class="line">		&#125;</span><br><span class="line">		ln := layerNorm(row, <span class="number">1e-5</span>)</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; tb.DModel; j++ &#123;</span><br><span class="line">			residual2.Set(i, j, ln.AtVec(j))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> residual2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 字符级Transformer模型 ==========</span></span><br><span class="line"><span class="keyword">type</span> CharTransformer <span class="keyword">struct</span> &#123;</span><br><span class="line">	VocabSize     <span class="type">int</span>             <span class="comment">// 词汇表大小</span></span><br><span class="line">	DModel        <span class="type">int</span>             <span class="comment">// 模型维度</span></span><br><span class="line">	MaxSeqLen     <span class="type">int</span>             <span class="comment">// 最大序列长度</span></span><br><span class="line">	Embedding     *mat.Dense      <span class="comment">// 字符嵌入矩阵 [vocab_size, d_model]</span></span><br><span class="line">	PosEncoding   *PositionalEncoding <span class="comment">// 位置编码</span></span><br><span class="line">	Transformer   *TransformerBlock   <span class="comment">// Transformer编码块</span></span><br><span class="line">	OutputLayer   *mat.Dense      <span class="comment">// 输出层 [d_model, vocab_size]</span></span><br><span class="line">	CharToIdx     <span class="keyword">map</span>[<span class="type">rune</span>]<span class="type">int</span>    <span class="comment">// 字符到索引的映射</span></span><br><span class="line">	IdxToChar     []<span class="type">rune</span>          <span class="comment">// 索引到字符的映射</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建字符级Transformer模型</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewCharTransformer</span><span class="params">(vocab <span class="type">string</span>, dModel, maxSeqLen <span class="type">int</span>)</span></span> *CharTransformer &#123;</span><br><span class="line">	vocabSize := <span class="built_in">len</span>(vocab)</span><br><span class="line">	charToIdx := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">rune</span>]<span class="type">int</span>)</span><br><span class="line">	idxToChar := <span class="built_in">make</span>([]<span class="type">rune</span>, vocabSize)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 构建字符索引映射</span></span><br><span class="line">	<span class="keyword">for</span> i, c := <span class="keyword">range</span> vocab &#123;</span><br><span class="line">		charToIdx[c] = i</span><br><span class="line">		idxToChar[i] = c</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// Xavier初始化</span></span><br><span class="line">	scale := math.Sqrt(<span class="number">2.0</span> / <span class="type">float64</span>(dModel))</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> &amp;CharTransformer&#123;</span><br><span class="line">		VocabSize:   vocabSize,</span><br><span class="line">		DModel:      dModel,</span><br><span class="line">		MaxSeqLen:   maxSeqLen,</span><br><span class="line">		Embedding:   mat.NewDense(vocabSize, dModel, randWeights(vocabSize*dModel, scale)),</span><br><span class="line">		PosEncoding: NewPositionalEncoding(dModel, maxSeqLen),</span><br><span class="line">		Transformer: NewTransformerBlock(dModel, dModel*<span class="number">4</span>),</span><br><span class="line">		OutputLayer: mat.NewDense(dModel, vocabSize, randWeights(dModel*vocabSize, scale)),</span><br><span class="line">		CharToIdx:   charToIdx,</span><br><span class="line">		IdxToChar:   idxToChar,</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将文本编码为嵌入向量 + 位置编码</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *CharTransformer)</span></span> Encode(text <span class="type">string</span>) *mat.Dense &#123;</span><br><span class="line">	seqLen := min(<span class="built_in">len</span>(text), m.MaxSeqLen)</span><br><span class="line">	x := mat.NewDense(seqLen, m.DModel, <span class="literal">nil</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 字符嵌入查找</span></span><br><span class="line">	<span class="keyword">for</span> i, c := <span class="keyword">range</span> text &#123;</span><br><span class="line">		<span class="keyword">if</span> i &gt;= m.MaxSeqLen &#123;</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> idx, ok := m.CharToIdx[c]; ok &#123;</span><br><span class="line">			<span class="comment">// 从嵌入矩阵中复制对应行</span></span><br><span class="line">			<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; m.DModel; j++ &#123;</span><br><span class="line">				x.Set(i, j, m.Embedding.At(idx, j))</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 添加位置编码</span></span><br><span class="line">	<span class="keyword">return</span> m.PosEncoding.Forward(x)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 前向传播：预测下一个字符</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *CharTransformer)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">	<span class="comment">// Transformer编码</span></span><br><span class="line">	out := m.Transformer.Forward(x)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 取最后一个位置的输出用于预测</span></span><br><span class="line">	lastPos := out.RawMatrix().Rows - <span class="number">1</span></span><br><span class="line">	lastVec := mat.NewVecDense(m.DModel, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; m.DModel; j++ &#123;</span><br><span class="line">		lastVec.SetVec(j, out.At(lastPos, j))</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 投影到词汇表空间</span></span><br><span class="line">	logits := mat.NewVecDense(m.VocabSize, <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; m.VocabSize; j++ &#123;</span><br><span class="line">		sum := <span class="number">0.0</span></span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; m.DModel; i++ &#123;</span><br><span class="line">			sum += lastVec.AtVec(i) * m.OutputLayer.At(i, j)</span><br><span class="line">		&#125;</span><br><span class="line">		logits.SetVec(j, sum)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> logits.AsDense()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 预测下一个字符（带温度采样）</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *CharTransformer)</span></span> Predict(text <span class="type">string</span>) <span class="type">rune</span> &#123;</span><br><span class="line">	x := m.Encode(text)</span><br><span class="line">	logits := m.Forward(x)</span><br><span class="line">	probs := softmax(mat.NewVecDense(m.VocabSize, logits.RawMatrix().Data))</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 温度采样：temperature &lt; 1.0 使分布更尖锐，&gt; 1.0 使分布更平滑</span></span><br><span class="line">	temperature := <span class="number">0.8</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; probs.Len(); i++ &#123;</span><br><span class="line">		<span class="comment">// 调整概率分布：p^(1/temperature)</span></span><br><span class="line">		probs.SetVec(i, math.Pow(probs.AtVec(i), <span class="number">1.0</span>/temperature))</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 重新归一化</span></span><br><span class="line">	sum := <span class="number">0.0</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; probs.Len(); i++ &#123;</span><br><span class="line">		sum += probs.AtVec(i)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; probs.Len(); i++ &#123;</span><br><span class="line">		probs.SetVec(i, probs.AtVec(i)/sum)</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 轮盘赌采样</span></span><br><span class="line">	r := rand.Float64()</span><br><span class="line">	cum := <span class="number">0.0</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; probs.Len(); i++ &#123;</span><br><span class="line">		cum += probs.AtVec(i)</span><br><span class="line">		<span class="keyword">if</span> r &lt; cum &#123;</span><br><span class="line">			<span class="keyword">return</span> m.IdxToChar[i]</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> m.IdxToChar[<span class="number">0</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 生成指定长度的文本</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *CharTransformer)</span></span> Generate(prompt <span class="type">string</span>, length <span class="type">int</span>) <span class="type">string</span> &#123;</span><br><span class="line">	result := prompt</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; length; i++ &#123;</span><br><span class="line">		nextChar := m.Predict(result)</span><br><span class="line">		result += <span class="type">string</span>(nextChar)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> result</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== Adam优化器（简化版） ==========</span></span><br><span class="line"><span class="keyword">type</span> AdamOptimizer <span class="keyword">struct</span> &#123;</span><br><span class="line">	Lr     <span class="type">float64</span>               <span class="comment">// 学习率</span></span><br><span class="line">	Beta1  <span class="type">float64</span>               <span class="comment">// 一阶矩估计衰减率</span></span><br><span class="line">	Beta2  <span class="type">float64</span>               <span class="comment">// 二阶矩估计衰减率</span></span><br><span class="line">	Eps    <span class="type">float64</span>               <span class="comment">// 数值稳定性常数</span></span><br><span class="line">	T      <span class="type">int</span>                   <span class="comment">// 时间步</span></span><br><span class="line">	M      <span class="keyword">map</span>[<span class="type">string</span>]*mat.Dense <span class="comment">// 一阶矩估计</span></span><br><span class="line">	V      <span class="keyword">map</span>[<span class="type">string</span>]*mat.Dense <span class="comment">// 二阶矩估计</span></span><br><span class="line">	Params <span class="keyword">map</span>[<span class="type">string</span>]*mat.Dense <span class="comment">// 可训练参数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建Adam优化器</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewAdamOptimizer</span><span class="params">(lr <span class="type">float64</span>)</span></span> *AdamOptimizer &#123;</span><br><span class="line">	<span class="keyword">return</span> &amp;AdamOptimizer&#123;</span><br><span class="line">		Lr:     lr,</span><br><span class="line">		Beta1:  <span class="number">0.9</span>,</span><br><span class="line">		Beta2:  <span class="number">0.999</span>,</span><br><span class="line">		Eps:    <span class="number">1e-8</span>,</span><br><span class="line">		T:      <span class="number">0</span>,</span><br><span class="line">		M:      <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]*mat.Dense),</span><br><span class="line">		V:      <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]*mat.Dense),</span><br><span class="line">		Params: <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="type">string</span>]*mat.Dense),</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注册可训练参数</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(opt *AdamOptimizer)</span></span> Register(name <span class="type">string</span>, param *mat.Dense) &#123;</span><br><span class="line">	opt.Params[name] = param</span><br><span class="line">	rows, cols := param.Dims()</span><br><span class="line">	<span class="comment">// 初始化一阶和二阶矩为零</span></span><br><span class="line">	opt.M[name] = mat.NewDense(rows, cols, <span class="built_in">make</span>([]<span class="type">float64</span>, rows*cols))</span><br><span class="line">	opt.V[name] = mat.NewDense(rows, cols, <span class="built_in">make</span>([]<span class="type">float64</span>, rows*cols))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行单步优化</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(opt *AdamOptimizer)</span></span> Step(name <span class="type">string</span>, grad *mat.Dense) &#123;</span><br><span class="line">	opt.T++</span><br><span class="line">	m := opt.M[name]</span><br><span class="line">	v := opt.V[name]</span><br><span class="line">	param := opt.Params[name]</span><br><span class="line">	rows, cols := grad.Dims()</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新一阶矩估计: m_t = beta1 * m_&#123;t-1&#125; + (1 - beta1) * grad</span></span><br><span class="line">	mTemp := mat.NewDense(rows, cols, <span class="literal">nil</span>)</span><br><span class="line">	mTemp.Scale(opt.Beta1, m)</span><br><span class="line">	mTemp.Add(mTemp, mat.NewDense(rows, cols, <span class="literal">nil</span>).Scale(<span class="number">1</span>-opt.Beta1, grad))</span><br><span class="line">	m.Copy(mTemp)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 更新二阶矩估计: v_t = beta2 * v_&#123;t-1&#125; + (1 - beta2) * grad^2</span></span><br><span class="line">	vTemp := mat.NewDense(rows, cols, <span class="literal">nil</span>)</span><br><span class="line">	vTemp.Scale(opt.Beta2, v)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; rows; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; cols; j++ &#123;</span><br><span class="line">			g := grad.At(i, j)</span><br><span class="line">			vTemp.Set(i, j, vTemp.At(i, j)+(<span class="number">1</span>-opt.Beta2)*g*g)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	v.Copy(vTemp)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 偏差校正</span></span><br><span class="line">	mHat := mat.NewDense(rows, cols, <span class="literal">nil</span>)</span><br><span class="line">	mHat.Scale(<span class="number">1.0</span>/(<span class="number">1.0</span>-math.Pow(opt.Beta1, <span class="type">float64</span>(opt.T))), m)</span><br><span class="line">	</span><br><span class="line">	vHat := mat.NewDense(rows, cols, <span class="literal">nil</span>)</span><br><span class="line">	vHat.Scale(<span class="number">1.0</span>/(<span class="number">1.0</span>-math.Pow(opt.Beta2, <span class="type">float64</span>(opt.T))), v)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 参数更新: theta_t = theta_&#123;t-1&#125; - lr * m_hat / (sqrt(v_hat) + eps)</span></span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; rows; i++ &#123;</span><br><span class="line">		<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; cols; j++ &#123;</span><br><span class="line">			update := opt.Lr * mHat.At(i, j) / (math.Sqrt(vHat.At(i, j)) + opt.Eps)</span><br><span class="line">			param.Set(i, j, param.At(i, j)-update)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 损失函数：交叉熵 ==========</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">crossEntropyLoss</span><span class="params">(logits *mat.VecDense, targetIdx <span class="type">int</span>)</span></span> (<span class="type">float64</span>, *mat.VecDense) &#123;</span><br><span class="line">	probs := softmax(logits)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 交叉熵损失: -log(p_target)</span></span><br><span class="line">	loss := -math.Log(probs.AtVec(targetIdx) + <span class="number">1e-10</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 梯度: dL/dz = p_i - y_i (y_i是one-hot目标)</span></span><br><span class="line">	grad := mat.NewVecDense(logits.Len(), <span class="literal">nil</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; logits.Len(); i++ &#123;</span><br><span class="line">		<span class="keyword">if</span> i == targetIdx &#123;</span><br><span class="line">			grad.SetVec(i, probs.AtVec(i)<span class="number">-1.0</span>) <span class="comment">// 目标类: p_i - 1</span></span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			grad.SetVec(i, probs.AtVec(i))     <span class="comment">// 非目标类: p_i</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> loss, grad</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 模型序列化 ==========</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m *CharTransformer)</span></span> Save(filename <span class="type">string</span>) <span class="type">error</span> &#123;</span><br><span class="line">	file, err := os.Create(filename)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> file.Close()</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 使用gob进行二进制序列化</span></span><br><span class="line">	encoder := gob.NewEncoder(file)</span><br><span class="line">	<span class="keyword">return</span> encoder.Encode(m)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">LoadCharTransformer</span><span class="params">(filename <span class="type">string</span>)</span></span> (*CharTransformer, <span class="type">error</span>) &#123;</span><br><span class="line">	file, err := os.Open(filename)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">defer</span> file.Close()</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">var</span> model CharTransformer</span><br><span class="line">	decoder := gob.NewDecoder(file)</span><br><span class="line">	<span class="keyword">if</span> err := decoder.Decode(&amp;model); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &amp;model, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 训练循环（简化版） ==========</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">train</span><span class="params">(model *CharTransformer, text <span class="type">string</span>, epochs, seqLen <span class="type">int</span>, lr <span class="type">float64</span>)</span></span> &#123;</span><br><span class="line">	<span class="comment">// 注意：完整反向传播需要为每个操作实现梯度计算</span></span><br><span class="line">	<span class="comment">// 本示例为教学目的简化训练过程，仅演示框架</span></span><br><span class="line">	<span class="comment">// 实际应用应使用自动微分库（如Gorgonia）实现完整梯度</span></span><br><span class="line">	</span><br><span class="line">	chars := []<span class="type">rune</span>(text)</span><br><span class="line">	<span class="keyword">for</span> epoch := <span class="number">0</span>; epoch &lt; epochs; epoch++ &#123;</span><br><span class="line">		totalLoss := <span class="number">0.0</span></span><br><span class="line">		count := <span class="number">0</span></span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 滑动窗口遍历文本</span></span><br><span class="line">		<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(chars)-seqLen; i++ &#123;</span><br><span class="line">			<span class="comment">// 构造输入序列和目标字符</span></span><br><span class="line">			input := <span class="type">string</span>(chars[i : i+seqLen])</span><br><span class="line">			targetChar := chars[i+seqLen]</span><br><span class="line">			targetIdx, ok := model.CharToIdx[targetChar]</span><br><span class="line">			<span class="keyword">if</span> !ok &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 前向传播</span></span><br><span class="line">			x := model.Encode(input)</span><br><span class="line">			logits := model.Forward(x)</span><br><span class="line">			logitsVec := mat.NewVecDense(model.VocabSize, logits.RawMatrix().Data)</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 计算损失和梯度</span></span><br><span class="line">			loss, grad := crossEntropyLoss(logitsVec, targetIdx)</span><br><span class="line">			totalLoss += loss</span><br><span class="line">			count++</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// 简化更新：仅更新输出层（完整训练需反向传播到所有层）</span></span><br><span class="line">			<span class="comment">// 实际应用中应实现完整的反向传播链</span></span><br><span class="line">			rows, cols := model.OutputLayer.Dims()</span><br><span class="line">			<span class="keyword">for</span> j := <span class="number">0</span>; j &lt; cols; j++ &#123;</span><br><span class="line">				<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; rows; i++ &#123;</span><br><span class="line">					<span class="comment">// 梯度下降更新</span></span><br><span class="line">					model.OutputLayer.Set(i, j, model.OutputLayer.At(i, j)-lr*grad.AtVec(j))</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> count &gt; <span class="number">0</span> &#123;</span><br><span class="line">			fmt.Printf(<span class="string">&quot;第 %d 轮训练, 平均损失: %.4f\n&quot;</span>, epoch+<span class="number">1</span>, totalLoss/<span class="type">float64</span>(count))</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 辅助函数 ==========</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">min</span><span class="params">(a, b <span class="type">int</span>)</span></span> <span class="type">int</span> &#123;</span><br><span class="line">	<span class="keyword">if</span> a &lt; b &#123;</span><br><span class="line">		<span class="keyword">return</span> a</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ========== 主程序 ==========</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	rand.Seed(time.Now().UnixNano())</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1. 定义字符集（支持英文、标点和换行）</span></span><br><span class="line">	vocab := <span class="string">&quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ,.!?&#x27;\n&quot;</span></span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 2. 创建模型（小模型适合CPU训练）</span></span><br><span class="line">	dModel := <span class="number">32</span>      <span class="comment">// 模型维度</span></span><br><span class="line">	maxSeqLen := <span class="number">32</span>   <span class="comment">// 最大序列长度</span></span><br><span class="line">	model := NewCharTransformer(vocab, dModel, maxSeqLen)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 3. 训练数据（莎士比亚风格短文本）</span></span><br><span class="line">	trainingText := <span class="string">`To be or not to be that is the question</span></span><br><span class="line"><span class="string">Whether tis nobler in the mind to suffer</span></span><br><span class="line"><span class="string">The slings and arrows of outrageous fortune</span></span><br><span class="line"><span class="string">Or to take arms against a sea of troubles</span></span><br><span class="line"><span class="string">And by opposing end them`</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 4. 训练模型（简化训练，完整反向传播需更多代码）</span></span><br><span class="line">	fmt.Println(<span class="string">&quot;开始训练模型（简化版，仅演示训练流程）...&quot;</span>)</span><br><span class="line">	train(model, trainingText, <span class="number">100</span>, <span class="number">16</span>, <span class="number">0.01</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 5. 保存模型到文件</span></span><br><span class="line">	modelPath := <span class="string">&quot;transformer_model.gob&quot;</span></span><br><span class="line">	<span class="keyword">if</span> err := model.Save(modelPath); err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">&quot;保存模型失败: %v&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Printf(<span class="string">&quot;✅ 模型已保存到 %s\n&quot;</span>, modelPath)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 6. 重新加载模型验证</span></span><br><span class="line">	loadedModel, err := LoadCharTransformer(modelPath)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">&quot;加载模型失败: %v&quot;</span>, err)</span><br><span class="line">	&#125;</span><br><span class="line">	fmt.Println(<span class="string">&quot;✅ 模型加载成功&quot;</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 7. 交互式文本生成</span></span><br><span class="line">	fmt.Println(<span class="string">&quot;\n&quot;</span> + strings.Repeat(<span class="string">&quot;=&quot;</span>, <span class="number">50</span>))</span><br><span class="line">	fmt.Println(<span class="string">&quot;🤖 交互式文本生成器（输入&#x27;quit&#x27;退出）&quot;</span>)</span><br><span class="line">	fmt.Println(strings.Repeat(<span class="string">&quot;=&quot;</span>, <span class="number">50</span>))</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		fmt.Print(<span class="string">&quot;\n请输入提示文本: &quot;</span>)</span><br><span class="line">		<span class="keyword">var</span> prompt <span class="type">string</span></span><br><span class="line">		fmt.Scanln(&amp;prompt)</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> prompt == <span class="string">&quot;quit&quot;</span> &#123;</span><br><span class="line">			fmt.Println(<span class="string">&quot;👋 再见！&quot;</span>)</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">if</span> prompt == <span class="string">&quot;&quot;</span> &#123;</span><br><span class="line">			prompt = <span class="string">&quot;To be&quot;</span></span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 生成50个字符的文本</span></span><br><span class="line">		generated := loadedModel.Generate(prompt, <span class="number">50</span>)</span><br><span class="line">		fmt.Printf(<span class="string">&quot;\n✨ 生成结果:\n%s\n&quot;</span>, generated)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 需要导入strings包用于格式化输出</span></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;strings&quot;</span></span><br></pre></td></tr></table></figure><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><h3 id="1-创建项目并安装依赖"><a href="#1-创建项目并安装依赖" class="headerlink" title="1. 创建项目并安装依赖"></a>1. 创建项目并安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建项目目录</span></span><br><span class="line"><span class="built_in">mkdir</span> go-transformer &amp;&amp; <span class="built_in">cd</span> go-transformer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化Go模块</span></span><br><span class="line">go mod init transformer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装数值计算库</span></span><br><span class="line">go get gonum.org/v1/gonum/mat</span><br></pre></td></tr></table></figure><h3 id="2-保存代码为-main-go-并运行"><a href="#2-保存代码为-main-go-并运行" class="headerlink" title="2. 保存代码为 main.go 并运行"></a>2. 保存代码为 <code>main.go</code> 并运行</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go run main.go</span><br></pre></td></tr></table></figure><h3 id="3-交互示例"><a href="#3-交互示例" class="headerlink" title="3. 交互示例"></a>3. 交互示例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">开始训练模型（简化版，仅演示训练流程）...</span><br><span class="line">第 1 轮训练, 平均损失: 3.6241</span><br><span class="line">第 2 轮训练, 平均损失: 3.5128</span><br><span class="line">...</span><br><span class="line">第 100 轮训练, 平均损失: 2.8745</span><br><span class="line">✅ 模型已保存到 transformer_model.gob</span><br><span class="line">✅ 模型加载成功</span><br><span class="line"></span><br><span class="line">==================================================</span><br><span class="line">🤖 交互式文本生成器（输入&#x27;quit&#x27;退出）</span><br><span class="line">==================================================</span><br><span class="line"></span><br><span class="line">请输入提示文本: To be</span><br><span class="line"></span><br><span class="line">✨ 生成结果:</span><br><span class="line">To be or not to be that is the question of the mind to suffer the slings and arrows of</span><br><span class="line"></span><br><span class="line">请输入提示文本: The slings</span><br><span class="line"></span><br><span class="line">✨ 生成结果:</span><br><span class="line">The slings and arrows of outrageous fortune or to take arms against a sea of troubles and</span><br></pre></td></tr></table></figure><h2 id="重要说明"><a href="#重要说明" class="headerlink" title="重要说明"></a>重要说明</h2><h3 id="🔑-核心设计特点"><a href="#🔑-核心设计特点" class="headerlink" title="🔑 核心设计特点"></a>🔑 核心设计特点</h3><ol><li><strong>极简实现</strong>：单层Transformer（32维），适合CPU快速验证</li><li><strong>字符级建模</strong>：直接预测下一个字符，无需分词</li><li><strong>完整流程</strong>：训练 → 保存 → 加载 → 交互生成</li><li><strong>教学友好</strong>：每行关键代码均有中文注释，清晰展示Transformer核心机制</li></ol><h3 id="⚠️-注意事项"><a href="#⚠️-注意事项" class="headerlink" title="⚠️ 注意事项"></a>⚠️ 注意事项</h3><ol><li><strong>简化训练</strong>：为保持代码精简（&lt;600行），训练部分仅更新输出层权重<ul><li>完整训练需实现所有层的反向传播（代码量将增加3-5倍）</li><li>生产环境建议使用<a target="_blank" rel="noopener" href="https://github.com/gorgonia/gorgonia">Gorgonia</a>等自动微分库</li></ul></li><li><strong>模型能力</strong>：小模型（32维）适合教学演示，生成文本质量有限<ul><li>提升效果：增大d_model（如128）、增加训练数据、完整实现反向传播</li></ul></li><li><strong>序列化</strong>：使用gob编码，确保所有结构体字段<strong>首字母大写</strong>（已处理）</li></ol><h3 id="💡-扩展建议"><a href="#💡-扩展建议" class="headerlink" title="💡 扩展建议"></a>💡 扩展建议</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如需提升生成质量，可尝试：</span></span><br><span class="line"><span class="comment">// 1. 增大模型维度</span></span><br><span class="line">dModel := <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 使用更大训练集（如整个莎士比亚文集）</span></span><br><span class="line">trainingText := loadShakespeare() </span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 实现完整反向传播（需为每个操作添加梯度计算）</span></span><br><span class="line"><span class="comment">// 4. 添加学习率调度、梯度裁剪等训练技巧</span></span><br></pre></td></tr></table></figure><p>使用Golang实现一个最简单的Transformer训练模型。</p><h2 id="极简Transformer实现：完整设计文档说明（面向初学者）"><a href="#极简Transformer实现：完整设计文档说明（面向初学者）" class="headerlink" title="极简Transformer实现：完整设计文档说明（面向初学者）"></a>极简Transformer实现：完整设计文档说明（面向初学者）</h2><h4 id="一、项目目标与设计哲学"><a href="#一、项目目标与设计哲学" class="headerlink" title="一、项目目标与设计哲学"></a>一、项目目标与设计哲学</h4><h4 id="🎯-核心目标"><a href="#🎯-核心目标" class="headerlink" title="🎯 核心目标"></a>🎯 核心目标</h4><ol><li><strong>教学优先</strong>：用最简代码（&lt;600行）完整展示Transformer核心机制</li><li><strong>端到端流程</strong>：训练 → 保存 → 加载 → 交互生成，形成完整闭环</li><li><strong>零外部依赖</strong>：仅需标准库 + gonum（纯CPU数值计算）</li><li><strong>字符级建模</strong>：避免分词复杂度，直接预测下一个字符</li></ol><h5 id="💡-设计哲学"><a href="#💡-设计哲学" class="headerlink" title="💡 设计哲学"></a>💡 设计哲学</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;展示核心思想 &gt; 追求工业级性能&quot;</span><br><span class="line">&quot;可读性 &gt; 代码精简度&quot;</span><br><span class="line">&quot;完整流程 &gt; 单点优化&quot;</span><br></pre></td></tr></table></figure><h4 id="二、整体架构设计"><a href="#二、整体架构设计" class="headerlink" title="二、整体架构设计"></a>二、整体架构设计</h4><h3 id="🌐-系统架构图"><a href="#🌐-系统架构图" class="headerlink" title="🌐 系统架构图"></a>🌐 系统架构图</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">输入文本 → [字符编码] → [嵌入层] → [位置编码] </span><br><span class="line">         → [Transformer块] → [输出层] → 预测下一个字符</span><br><span class="line">                ↑          ↑</span><br><span class="line">          [自注意力]   [前馈网络]</span><br><span class="line">                ↑          ↑</span><br><span class="line">          [残差连接]   [层归一化]</span><br></pre></td></tr></table></figure><h5 id="📦-模块划分"><a href="#📦-模块划分" class="headerlink" title="📦 模块划分"></a>📦 模块划分</h5><table><thead><tr><th>模块</th><th>功能</th><th>关键技术点</th></tr></thead><tbody><tr><td><strong>基础工具</strong></td><td>数学运算支持</td><td>Softmax, LayerNorm, 随机初始化</td></tr><tr><td><strong>位置编码</strong></td><td>注入序列位置信息</td><td>正弦&#x2F;余弦函数编码</td></tr><tr><td><strong>自注意力</strong></td><td>捕捉序列内部关系</td><td>Q&#x2F;K&#x2F;V计算, 缩放点积, Softmax</td></tr><tr><td><strong>前馈网络</strong></td><td>非线性特征变换</td><td>两层MLP + ReLU激活</td></tr><tr><td><strong>Transformer块</strong></td><td>核心计算单元</td><td>残差连接 + 层归一化</td></tr><tr><td><strong>字符模型</strong></td><td>完整语言模型</td><td>嵌入层 + 位置编码 + Transformer + 输出层</td></tr><tr><td><strong>训练系统</strong></td><td>参数优化</td><td>简化版Adam + 交叉熵损失</td></tr><tr><td><strong>序列化</strong></td><td>模型持久化</td><td>gob二进制编码</td></tr><tr><td><strong>交互接口</strong></td><td>用户体验</td><td>温度采样 + 轮盘赌选择</td></tr></tbody></table><h4 id="三、核心组件详解（含实现逻辑）"><a href="#三、核心组件详解（含实现逻辑）" class="headerlink" title="三、核心组件详解（含实现逻辑）"></a>三、核心组件详解（含实现逻辑）</h4><h5 id="🔑-1-基础工具函数"><a href="#🔑-1-基础工具函数" class="headerlink" title="🔑 1. 基础工具函数"></a>🔑 1. 基础工具函数</h5><h6 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h6><ul><li>提供数值计算基础能力</li><li>保证数值稳定性（防止exp溢出）</li></ul><h6 id="实现逻辑"><a href="#实现逻辑" class="headerlink" title="实现逻辑"></a>实现逻辑</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Softmax: 将 logits 转换为概率分布</span></span><br><span class="line"><span class="comment">// 关键技巧: 先减去最大值 (x - max(x)) 防止指数溢出</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">softmax</span><span class="params">(x *mat.VecDense)</span></span> *mat.VecDense &#123;</span><br><span class="line">    maxVal := findMax(x)          <span class="comment">// 步骤1: 找最大值</span></span><br><span class="line">    expVals := computeExp(x, maxVal) <span class="comment">// 步骤2: 计算 e^(x_i - max)</span></span><br><span class="line">    <span class="keyword">return</span> normalize(expVals)     <span class="comment">// 步骤3: 归一化为概率</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// LayerNorm: 对单个样本归一化（与BatchNorm不同）</span></span><br><span class="line"><span class="comment">// 公式: (x - mean) / sqrt(variance + eps)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">layerNorm</span><span class="params">(x *mat.VecDense, eps <span class="type">float64</span>)</span></span> *mat.VecDense &#123;</span><br><span class="line">    mean := computeMean(x)        <span class="comment">// 步骤1: 计算均值</span></span><br><span class="line">    variance := computeVariance(x, mean) <span class="comment">// 步骤2: 计算方差</span></span><br><span class="line">    <span class="keyword">return</span> normalizeByStats(x, mean, variance, eps) <span class="comment">// 步骤3: 归一化</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="初学者理解要点"><a href="#初学者理解要点" class="headerlink" title="初学者理解要点"></a>初学者理解要点</h6><p>✅ Softmax不是简单的指数归一化，<strong>必须先减最大值</strong>保证数值稳定<br>✅ LayerNorm是对<strong>单个样本</strong>的所有特征归一化（不是整个batch）<br>✅ eps (1e-5) 是防止除零的小常数</p><hr><h5 id="📍-2-位置编码-PositionalEncoding"><a href="#📍-2-位置编码-PositionalEncoding" class="headerlink" title="📍 2. 位置编码 (PositionalEncoding)"></a>📍 2. 位置编码 (PositionalEncoding)</h5><h6 id="设计目标-1"><a href="#设计目标-1" class="headerlink" title="设计目标"></a>设计目标</h6><ul><li>为Transformer注入序列顺序信息（原始Transformer无位置概念）</li><li>使用确定性函数避免可学习参数</li></ul><h6 id="实现逻辑-1"><a href="#实现逻辑-1" class="headerlink" title="实现逻辑"></a>实现逻辑</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 位置编码公式 (来自原始论文):</span></span><br><span class="line"><span class="comment">// PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))</span></span><br><span class="line"><span class="comment">// PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewPositionalEncoding</span><span class="params">(dModel, maxLen <span class="type">int</span>)</span></span> *PositionalEncoding &#123;</span><br><span class="line">    pe := 新建矩阵(maxLen, dModel)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> pos := <span class="number">0</span>; pos &lt; maxLen; pos++ &#123;</span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; dModel; i += <span class="number">2</span> &#123;</span><br><span class="line">            <span class="comment">// 计算波长: 10000^(2i/d_model)</span></span><br><span class="line">            wavelength := math.Pow(<span class="number">10000</span>, <span class="type">float64</span>(<span class="number">2</span>*i)/<span class="type">float64</span>(dModel))</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 偶数维度: 正弦函数</span></span><br><span class="line">            pe.Set(pos, i, math.Sin(<span class="type">float64</span>(pos) / wavelength))</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 奇数维度: 余弦函数</span></span><br><span class="line">            <span class="keyword">if</span> i+<span class="number">1</span> &lt; dModel &#123;</span><br><span class="line">                pe.Set(pos, i+<span class="number">1</span>, math.Cos(<span class="type">float64</span>(pos) / wavelength))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> &amp;PositionalEncoding&#123;pe&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="初学者理解要点-1"><a href="#初学者理解要点-1" class="headerlink" title="初学者理解要点"></a>初学者理解要点</h6><p>✅ 为什么需要位置编码？<strong>Transformer本身不知道”顺序”<strong>，所有位置平等处理<br>✅ 为什么用sin&#x2F;cos？</strong>不同频率的波可编码不同尺度的位置关系</strong><br>✅ 为什么10000？<strong>经验值，确保位置编码在合理范围内变化</strong></p><hr><h5 id="👁️-3-自注意力机制-SelfAttention"><a href="#👁️-3-自注意力机制-SelfAttention" class="headerlink" title="👁️ 3. 自注意力机制 (SelfAttention)"></a>👁️ 3. 自注意力机制 (SelfAttention)</h5><h6 id="设计目标-2"><a href="#设计目标-2" class="headerlink" title="设计目标"></a>设计目标</h6><ul><li>让序列中每个位置能”关注”其他所有位置</li><li>通过Q&#x2F;K&#x2F;V机制动态计算注意力权重</li></ul><h6 id="实现逻辑（5步流程）"><a href="#实现逻辑（5步流程）" class="headerlink" title="实现逻辑（5步流程）"></a>实现逻辑（5步流程）</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输入: X [seq_len, d_model]</span></span><br><span class="line"><span class="comment">// 输出: 加权融合后的表示 [seq_len, d_model]</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sa *SelfAttention)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">    <span class="comment">// 步骤1: 计算Q/K/V (线性变换)</span></span><br><span class="line">    Q = X * Wq  <span class="comment">// [seq_len, d_model]</span></span><br><span class="line">    K = X * Wk  <span class="comment">// [seq_len, d_model]</span></span><br><span class="line">    V = X * Wv  <span class="comment">// [seq_len, d_model]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 步骤2: 计算注意力分数 (缩放点积)</span></span><br><span class="line">    scores = Q * K^T / sqrt(d_k)  <span class="comment">// [seq_len, seq_len]</span></span><br><span class="line">    <span class="comment">// 为什么缩放？防止大d_k导致梯度消失</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 步骤3: 行级Softmax (得到注意力权重)</span></span><br><span class="line">    attn_weights = softmax(scores)  <span class="comment">// 每行和为1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 步骤4: 加权求和</span></span><br><span class="line">    output = attn_weights * V  <span class="comment">// [seq_len, d_model]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 步骤5: 输出投影</span></span><br><span class="line">    <span class="keyword">return</span> output * Wo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="初学者理解要点-2"><a href="#初学者理解要点-2" class="headerlink" title="初学者理解要点"></a>初学者理解要点</h6><p>✅ <strong>Q (Query)</strong>: “我在找什么”<br>✅ <strong>K (Key)</strong>: “我有什么特征”<br>✅ <strong>V (Value)</strong>: “我的实际内容是什么”<br>✅ <strong>缩放因子 1&#x2F;√d_k</strong>: 防止点积过大导致Softmax梯度消失<br>✅ <strong>单头简化</strong>: 完整Transformer有多头，本实现用单头保持简洁</p><hr><h5 id="⚙️-4-前馈网络-FeedForward"><a href="#⚙️-4-前馈网络-FeedForward" class="headerlink" title="⚙️ 4. 前馈网络 (FeedForward)"></a>⚙️ 4. 前馈网络 (FeedForward)</h5><h6 id="设计目标-3"><a href="#设计目标-3" class="headerlink" title="设计目标"></a>设计目标</h6><ul><li>为每个位置独立应用非线性变换</li><li>增加模型表达能力</li></ul><h6 id="实现逻辑-2"><a href="#实现逻辑-2" class="headerlink" title="实现逻辑"></a>实现逻辑</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 两层全连接网络 + ReLU激活</span></span><br><span class="line"><span class="comment">// 公式: FFN(x) = max(0, x*W1 + b1) * W2 + b2</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(ff *FeedForward)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">    <span class="comment">// 第一层: 线性变换 + ReLU</span></span><br><span class="line">    hidden = ReLU(x * W1 + b1)  <span class="comment">// [seq_len, d_ff]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 第二层: 线性变换 (无激活)</span></span><br><span class="line">    output = hidden * W2 + b2   <span class="comment">// [seq_len, d_model]</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="作为初学者理解要点"><a href="#作为初学者理解要点" class="headerlink" title="作为初学者理解要点"></a>作为初学者理解要点</h6><p>✅ <strong>为什么需要FFN？</strong> 自注意力只做加权平均，需要非线性变换增强表达力<br>✅ <strong>为什么中间层更大？</strong> (d_ff &#x3D; 4*d_model) 提供”信息瓶颈”后的扩展空间<br>✅ <strong>为什么第二层无激活？</strong> 保持输出可与其他层残差连接</p><hr><h5 id="🔗-5-Transformer块-TransformerBlock"><a href="#🔗-5-Transformer块-TransformerBlock" class="headerlink" title="🔗 5. Transformer块 (TransformerBlock)"></a>🔗 5. Transformer块 (TransformerBlock)</h5><h6 id="设计目标-4"><a href="#设计目标-4" class="headerlink" title="设计目标"></a>设计目标</h6><ul><li>组合自注意力和前馈网络</li><li>通过残差连接和层归一化稳定训练</li></ul><h6 id="实现逻辑（带残差连接）"><a href="#实现逻辑（带残差连接）" class="headerlink" title="实现逻辑（带残差连接）"></a>实现逻辑（带残差连接）</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(tb *TransformerBlock)</span></span> Forward(x *mat.Dense) *mat.Dense &#123;</span><br><span class="line">    <span class="comment">// 子层1: 自注意力 + 残差连接 + 层归一化</span></span><br><span class="line">    attn_out = SelfAttention(x)</span><br><span class="line">    x1 = LayerNorm(x + attn_out)  <span class="comment">// 残差: x + attn(x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 子层2: 前馈网络 + 残差连接 + 层归一化</span></span><br><span class="line">    ff_out = FeedForward(x1)</span><br><span class="line">    x2 = LayerNorm(x1 + ff_out)   <span class="comment">// 残差: x1 + ff(x1)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="初学者理解要点-3"><a href="#初学者理解要点-3" class="headerlink" title="初学者理解要点"></a>初学者理解要点</h6><p>✅ <strong>残差连接 (Residual Connection)</strong>: <code>output = input + sublayer(input)</code></p><ul><li>解决深层网络梯度消失问题</li><li>允许梯度直接回传到浅层<br>✅ <strong>层归一化位置</strong>: <strong>先残差后归一化</strong> (Post-LN) vs <strong>先归一化后残差</strong> (Pre-LN)</li><li>本实现采用Post-LN（原始Transformer）<br>✅ <strong>为什么需要两个子层？</strong> 自注意力捕获全局关系，FFN做位置级非线性变换</li></ul><hr><h5 id="🧠-6-字符级Transformer模型-CharTransformer"><a href="#🧠-6-字符级Transformer模型-CharTransformer" class="headerlink" title="🧠 6. 字符级Transformer模型 (CharTransformer)"></a>🧠 6. 字符级Transformer模型 (CharTransformer)</h5><h6 id="整体数据流"><a href="#整体数据流" class="headerlink" title="整体数据流"></a>整体数据流</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">输入文本 &quot;To be&quot; </span><br><span class="line">  ↓</span><br><span class="line">字符编码 [84, 111, 32, 98, 101]  // ASCII值</span><br><span class="line">  ↓</span><br><span class="line">嵌入查找 → [向量1, 向量2, ...]  // [5, 32] 矩阵</span><br><span class="line">  ↓</span><br><span class="line">+ 位置编码 → [增强位置信息的向量]</span><br><span class="line">  ↓</span><br><span class="line">Transformer块 → [上下文感知表示]</span><br><span class="line">  ↓</span><br><span class="line">取最后位置 → [32维向量]</span><br><span class="line">  ↓</span><br><span class="line">输出层投影 → [67维logits]  // 67个字符的分数</span><br><span class="line">  ↓</span><br><span class="line">Softmax → [概率分布]</span><br><span class="line">  ↓</span><br><span class="line">采样 → 下一个字符 &#x27; &#x27;</span><br></pre></td></tr></table></figure><h6 id="关键设计决策"><a href="#关键设计决策" class="headerlink" title="关键设计决策"></a>关键设计决策</h6><table><thead><tr><th>决策</th><th>原因</th><th>替代方案</th></tr></thead><tbody><tr><td><strong>字符级建模</strong></td><td>避免分词复杂度，适合教学</td><td>词级&#x2F;子词级（需BPE等）</td></tr><tr><td><strong>单层Transformer</strong></td><td>保持代码简洁</td><td>多层堆叠（增加3-5倍代码）</td></tr><tr><td><strong>d_model&#x3D;32</strong></td><td>CPU友好，快速验证</td><td>更大维度（128&#x2F;256）提升效果</td></tr><tr><td><strong>最大序列长32</strong></td><td>平衡上下文与计算量</td><td>更长序列（需更多内存）</td></tr></tbody></table><hr><h5 id="📉-7-训练系统（简化版）"><a href="#📉-7-训练系统（简化版）" class="headerlink" title="📉 7. 训练系统（简化版）"></a>📉 7. 训练系统（简化版）</h5><h4 id="为什么简化训练？"><a href="#为什么简化训练？" class="headerlink" title="为什么简化训练？"></a>为什么简化训练？</h4><p>完整反向传播需为<strong>每个操作实现梯度计算</strong>，代码量将增加3-5倍，严重影响可读性。<br>本实现聚焦<strong>前向传播完整性</strong> + <strong>训练流程演示</strong>，适合初学者理解整体流程。</p><h6 id="简化训练策略"><a href="#简化训练策略" class="headerlink" title="简化训练策略"></a>简化训练策略</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 仅更新输出层权重（完整训练需反向传播到所有层）</span></span><br><span class="line"><span class="keyword">for</span> 每个训练样本 &#123;</span><br><span class="line">    <span class="comment">// 1. 前向传播得到logits</span></span><br><span class="line">    logits = model.Forward(input)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 2. 计算损失和梯度</span></span><br><span class="line">    loss, grad = crossEntropyLoss(logits, target)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 3. 仅更新输出层（简化版）</span></span><br><span class="line">    model.OutputLayer -= learning_rate * grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 完整版应: </span></span><br><span class="line">    <span class="comment">//   - 计算Transformer块梯度</span></span><br><span class="line">    <span class="comment">//   - 计算自注意力梯度</span></span><br><span class="line">    <span class="comment">//   - 计算FFN梯度</span></span><br><span class="line">    <span class="comment">//   - 逐层反向传播</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="初学者正确理解"><a href="#初学者正确理解" class="headerlink" title="初学者正确理解"></a>初学者正确理解</h6><p>⚠️ <strong>这不是生产级训练</strong>，但完整展示了：</p><ul><li>数据准备（滑动窗口）</li><li>前向传播</li><li>损失计算</li><li>参数更新流程</li><li>模型保存&#x2F;加载</li></ul><p>✅ <strong>学习重点</strong>：理解训练循环结构，而非梯度计算细节<br>💡 <strong>进阶方向</strong>：学习自动微分库（Gorgonia）实现完整反向传播</p><hr><h5 id="💾-8-模型序列化-gob编码"><a href="#💾-8-模型序列化-gob编码" class="headerlink" title="💾 8. 模型序列化 (gob编码)"></a>💾 8. 模型序列化 (gob编码)</h5><h4 id="设计选择"><a href="#设计选择" class="headerlink" title="设计选择"></a>设计选择</h4><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th><th>本项目选择</th></tr></thead><tbody><tr><td><strong>gob</strong></td><td>Go原生，简单高效</td><td>仅Go可用</td><td>✅ 适合教学</td></tr><tr><td>JSON</td><td>人类可读</td><td>浮点精度损失</td><td>❌</td></tr><tr><td>Protocol Buffers</td><td>跨语言</td><td>需要schema定义</td><td>❌</td></tr></tbody></table><h6 id="关键实现细节"><a href="#关键实现细节" class="headerlink" title="关键实现细节"></a>关键实现细节</h6><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 必须导出所有字段（首字母大写）才能被gob序列化</span></span><br><span class="line"><span class="keyword">type</span> CharTransformer <span class="keyword">struct</span> &#123;</span><br><span class="line">    VocabSize   <span class="type">int</span>      <span class="comment">// ✅ 导出</span></span><br><span class="line">    dModel      <span class="type">int</span>      <span class="comment">// ❌ 不导出 → 序列化失败！</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="初学者陷阱"><a href="#初学者陷阱" class="headerlink" title="初学者陷阱"></a>初学者陷阱</h6><p>🔴 <strong>常见错误</strong>：结构体字段小写 → gob无法序列化 → 模型加载失败<br>✅ <strong>解决方案</strong>：所有需要保存的字段必须<strong>首字母大写</strong></p><hr><h4 id="四、训练与推理流程"><a href="#四、训练与推理流程" class="headerlink" title="四、训练与推理流程"></a>四、训练与推理流程</h4><h5 id="🔄-完整训练流程"><a href="#🔄-完整训练流程" class="headerlink" title="🔄 完整训练流程"></a>🔄 完整训练流程</h5><pre class="mermaid">graph TD
    A[准备训练数据] --> B[滑动窗口切分]
    B --> C{遍历每个样本}
    C --> D[字符编码 + 嵌入]
    D --> E[位置编码]
    E --> F[Transformer前向传播]
    F --> G[计算损失]
    G --> H[简化梯度更新]
    H --> I{是否完成epoch}
    I -- 否 --> C
    I -- 是 --> J[保存模型]</pre><h5 id="💬-交互生成流程"><a href="#💬-交互生成流程" class="headerlink" title="💬 交互生成流程"></a>💬 交互生成流程</h5><pre class="mermaid">graph LR
    A[用户输入提示] --> B[编码为嵌入]
    B --> C[Transformer推理]
    C --> D[输出概率分布]
    D --> E[温度采样]
    E --> F[选择下一个字符]
    F --> G{达到长度?}
    G -- 否 --> B
    G -- 是 --> H[返回生成文本]</pre><h6 id="温度采样原理"><a href="#温度采样原理" class="headerlink" title="温度采样原理"></a>温度采样原理</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">原始概率: [0.7, 0.2, 0.1]  // &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;</span><br><span class="line"></span><br><span class="line">温度=1.0: 保持原分布 → 倾向高概率字符</span><br><span class="line">温度=0.5: [0.85, 0.12, 0.03] → 更确定性，重复性高</span><br><span class="line">温度=2.0: [0.55, 0.28, 0.17] → 更随机，创造性高</span><br><span class="line"></span><br><span class="line">公式: p_i&#x27; = p_i^(1/temperature) / sum(p_j^(1/temperature))</span><br></pre></td></tr></table></figure><h4 id="五、效果评估与局限性"><a href="#五、效果评估与局限性" class="headerlink" title="五、效果评估与局限性"></a>五、效果评估与局限性</h4><h5 id="✅-预期效果（训练100轮后）"><a href="#✅-预期效果（训练100轮后）" class="headerlink" title="✅ 预期效果（训练100轮后）"></a>✅ 预期效果（训练100轮后）</h5><table><thead><tr><th>提示文本</th><th>生成示例</th><th>质量评估</th></tr></thead><tbody><tr><td><code>&quot;To be&quot;</code></td><td><code>&quot;To be or not to be that is the question of the&quot;</code></td><td>★★★☆☆ 基本语法正确，有莎士比亚风格</td></tr><tr><td><code>&quot;The slings&quot;</code></td><td><code>&quot;The slings and arrows of outrageous fortune or to&quot;</code></td><td>★★★☆☆ 能延续训练数据中的短语</td></tr><tr><td><code>&quot;Hello&quot;</code></td><td><code>&quot;Hello world to be or not to be that is the&quot;</code></td><td>★★☆☆☆ 未见数据，混合训练模式</td></tr></tbody></table><h5 id="⚠️-局限性说明"><a href="#⚠️-局限性说明" class="headerlink" title="⚠️ 局限性说明"></a>⚠️ 局限性说明</h5><table><thead><tr><th>限制</th><th>原因</th><th>改进方向</th></tr></thead><tbody><tr><td><strong>生成质量有限</strong></td><td>模型小(32维) + 训练简化</td><td>增大d_model，完整反向传播</td></tr><tr><td><strong>上下文短(32)</strong></td><td>内存&#x2F;CPU限制</td><td>优化实现，支持更长序列</td></tr><tr><td><strong>仅英文字符</strong></td><td>词汇表设计</td><td>扩展Unicode支持</td></tr><tr><td><strong>训练慢</strong></td><td>Go非数值计算最优语言</td><td>使用GPU库（如Gorgonia）</td></tr></tbody></table><h5 id="📊-性能基准（Intel-i7-CPU）"><a href="#📊-性能基准（Intel-i7-CPU）" class="headerlink" title="📊 性能基准（Intel i7 CPU）"></a>📊 性能基准（Intel i7 CPU）</h5><table><thead><tr><th>操作</th><th>耗时</th><th>说明</th></tr></thead><tbody><tr><td>单次前向传播</td><td>~2ms</td><td>32字符序列</td></tr><tr><td>生成50字符</td><td>~100ms</td><td>交互式体验流畅</td></tr><tr><td>100轮训练</td><td>~15秒</td><td>小数据集快速验证</td></tr></tbody></table><h4 id="六、学习路径建议（初学者）"><a href="#六、学习路径建议（初学者）" class="headerlink" title="六、学习路径建议（初学者）"></a>六、学习路径建议（初学者）</h4><h5 id="📖-推荐学习顺序"><a href="#📖-推荐学习顺序" class="headerlink" title="📖 推荐学习顺序"></a>📖 推荐学习顺序</h5><ol><li><p><strong>先理解概念</strong>（不看代码）：</p><ul><li>阅读《Attention Is All You Need》图2（模型架构图）</li><li>观看3Blue1Brown的Transformer可视化视频</li></ul></li><li><p><strong>再看代码实现</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按模块顺序阅读</span></span><br><span class="line">main.go          <span class="comment"># 整体流程</span></span><br><span class="line">→ 基础工具函数    <span class="comment"># 数学基础</span></span><br><span class="line">→ 位置编码       <span class="comment"># 序列位置处理</span></span><br><span class="line">→ 自注意力       <span class="comment"># 核心创新点</span></span><br><span class="line">→ 前馈网络       <span class="comment"># 非线性增强</span></span><br><span class="line">→ Transformer块  <span class="comment"># 组合逻辑</span></span><br><span class="line">→ 字符模型       <span class="comment"># 完整pipeline</span></span><br></pre></td></tr></table></figure></li><li><p><strong>动手实验</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实验1: 修改温度参数观察生成变化</span></span><br><span class="line">temperature = 0.5  <span class="comment"># 更确定</span></span><br><span class="line">temperature = 1.5  <span class="comment"># 更随机</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实验2: 扩展词汇表支持中文</span></span><br><span class="line">vocab = <span class="string">&quot;你好世界...&quot;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 实验3: 增大模型维度</span></span><br><span class="line">dModel = 64  <span class="comment"># 观察效果/速度变化</span></span><br></pre></td></tr></table></figure></li></ol><h5 id="💡-关键理解检查点"><a href="#💡-关键理解检查点" class="headerlink" title="💡 关键理解检查点"></a>💡 关键理解检查点</h5><p>完成以下任务证明真正理解：</p><ul><li><input disabled type="checkbox"> 能手动画出3个字符的自注意力计算过程</li><li><input disabled type="checkbox"> 能解释为什么需要位置编码</li><li><input disabled type="checkbox"> 能说明残差连接如何解决梯度消失</li><li><input disabled type="checkbox"> 能描述从输入到输出的完整数据流</li><li><input disabled type="checkbox"> 能修改温度参数并解释生成结果变化</li></ul><h4 id="七、完整代码结构（带注释索引）"><a href="#七、完整代码结构（带注释索引）" class="headerlink" title="七、完整代码结构（带注释索引）"></a>七、完整代码结构（带注释索引）</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main.go 完整结构</span></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 1. 基础工具 (行 15-50) =====</span></span><br><span class="line"><span class="comment">//   - 随机数生成</span></span><br><span class="line"><span class="comment">//   - Softmax实现</span></span><br><span class="line"><span class="comment">//   - LayerNorm实现</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 2. 位置编码 (行 52-90) =====</span></span><br><span class="line"><span class="comment">//   - 结构体定义</span></span><br><span class="line"><span class="comment">//   - 创建函数 (sin/cos公式)</span></span><br><span class="line"><span class="comment">//   - 前向传播 (添加到输入)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 3. 自注意力 (行 92-180) =====</span></span><br><span class="line"><span class="comment">//   - 结构体 (Q/K/V/Wo权重)</span></span><br><span class="line"><span class="comment">//   - 创建函数 (Xavier初始化)</span></span><br><span class="line"><span class="comment">//   - 前向传播 (5步流程)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 4. 前馈网络 (行 182-230) =====</span></span><br><span class="line"><span class="comment">//   - 结构体 (W1/b1/W2/b2)</span></span><br><span class="line"><span class="comment">//   - 创建函数</span></span><br><span class="line"><span class="comment">//   - 前向传播 (ReLU激活)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 5. Transformer块 (行 232-290) =====</span></span><br><span class="line"><span class="comment">//   - 结构体组合</span></span><br><span class="line"><span class="comment">//   - 前向传播 (残差+归一化)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 6. 字符模型 (行 292-420) =====</span></span><br><span class="line"><span class="comment">//   - 完整pipeline</span></span><br><span class="line"><span class="comment">//   - 编码/前向/预测/生成</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 7. 优化器 (行 422-500) =====</span></span><br><span class="line"><span class="comment">//   - Adam简化实现</span></span><br><span class="line"><span class="comment">//   - 参数注册/更新</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 8. 损失函数 (行 502-530) =====</span></span><br><span class="line"><span class="comment">//   - 交叉熵计算</span></span><br><span class="line"><span class="comment">//   - 梯度推导</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 9. 序列化 (行 532-560) =====</span></span><br><span class="line"><span class="comment">//   - gob保存/加载</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 10. 训练循环 (行 562-620) =====</span></span><br><span class="line"><span class="comment">//   - 滑动窗口</span></span><br><span class="line"><span class="comment">//   - 简化训练流程</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ===== 11. 主程序 (行 622-700) =====</span></span><br><span class="line"><span class="comment">//   - 模型创建</span></span><br><span class="line"><span class="comment">//   - 训练执行</span></span><br><span class="line"><span class="comment">//   - 交互生成</span></span><br></pre></td></tr></table></figure><h4 id="八、常见问题解答（FAQ）"><a href="#八、常见问题解答（FAQ）" class="headerlink" title="八、常见问题解答（FAQ）"></a>八、常见问题解答（FAQ）</h4><h5 id="❓-为什么不用多头注意力？"><a href="#❓-为什么不用多头注意力？" class="headerlink" title="❓ 为什么不用多头注意力？"></a>❓ 为什么不用多头注意力？</h5><p>教学目的：单头已完整展示注意力机制本质。多头只是并行多个单头+拼接，增加代码复杂度但不改变核心思想。</p><h5 id="❓-为什么训练只更新输出层？"><a href="#❓-为什么训练只更新输出层？" class="headerlink" title="❓ 为什么训练只更新输出层？"></a>❓ 为什么训练只更新输出层？</h5><p>完整反向传播需为每个矩阵操作实现梯度，代码量将增加300+行，严重影响可读性。本实现聚焦<strong>前向传播完整性</strong>和<strong>训练流程演示</strong>。</p><h5 id="❓-能生成中文吗？"><a href="#❓-能生成中文吗？" class="headerlink" title="❓ 能生成中文吗？"></a>❓ 能生成中文吗？</h5><p>可以！只需扩展词汇表：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vocab := <span class="string">&quot;你好世界abcdefghijklmnopqrstuvwxyz...&quot;</span> </span><br></pre></td></tr></table></figure><p>但需要中文训练数据，且小模型效果有限。</p><h5 id="❓-如何提升生成质量？"><a href="#❓-如何提升生成质量？" class="headerlink" title="❓ 如何提升生成质量？"></a>❓ 如何提升生成质量？</h5><ol><li>增大d_model (64&#x2F;128)</li><li>使用更大训练集（整个莎士比亚文集）</li><li>实现完整反向传播（需自动微分库）</li><li>增加Transformer层数</li><li>添加Dropout防止过拟合</li></ol><h5 id="❓-为什么不用PyTorch-x2F-TensorFlow？"><a href="#❓-为什么不用PyTorch-x2F-TensorFlow？" class="headerlink" title="❓ 为什么不用PyTorch&#x2F;TensorFlow？"></a>❓ 为什么不用PyTorch&#x2F;TensorFlow？</h5><p>本项目目标是<strong>理解Transformer本质</strong>，而非追求性能。Go实现迫使你理解每个操作的数学本质，避免”调库工程师”陷阱。</p><hr><h4 id="总结：初学者收获清单"><a href="#总结：初学者收获清单" class="headerlink" title="总结：初学者收获清单"></a>总结：初学者收获清单</h4><p>完成本项目后，你将理解：</p><ul><li>✅ Transformer的5大核心组件及作用</li><li>✅ 自注意力的数学原理和计算流程</li><li>✅ 位置编码的必要性和实现方式</li><li>✅ 残差连接和层归一化如何稳定训练</li><li>✅ 完整的训练-保存-推理pipeline</li><li>✅ 字符级语言模型的工作原理</li><li>✅ 温度采样对生成多样性的影响</li><li>✅ 模型序列化的实践方法</li></ul><p><strong>最重要收获</strong>：你将拥有一个<strong>可运行、可修改、可理解</strong>的Transformer实现，这是深入学习NLP的坚实基础，最终通向AGI的来时路！</p></div><div class="article-licensing box"><div class="licensing-title"><p>基于Go语言实现Transformer模型（包含训练、保存、加载和交互式文本生成功能）</p><p><a href="https://www.wdft.com/3bdefda4.html">https://www.wdft.com/3bdefda4.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Jaco Liu</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2026-01-19</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2026-01-31</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a><a class="link-muted mr-2" rel="tag" href="/tags/LLM/">LLM</a><a class="link-muted mr-2" rel="tag" href="/tags/Go/">Go</a><a class="link-muted mr-2" rel="tag" href="/tags/Go-LLM/">Go-LLM</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=627845fc01dad800199bf3d4&amp;product=inline-share-buttons" defer></script></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/fae079ad.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">【sync】深入解构Go标准库Go标准库sync包的并发原语的原理以及实践开发中注意的要点</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/8f9e85.html"><span class="level-item">用SOP搭建你创业的“自动驾驶系统”（新农业和跨境电商实战版典型为例）基本商业概念理解</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><script src="/js/mermaid.min.js"></script></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen order-3"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#使用说明"><span class="level-left"><span class="level-item">1</span><span class="level-item">使用说明</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#1-创建项目并安装依赖"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">1. 创建项目并安装依赖</span></span></a></li><li><a class="level is-mobile" href="#2-保存代码为-main-go-并运行"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">2. 保存代码为 main.go 并运行</span></span></a></li><li><a class="level is-mobile" href="#3-交互示例"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">3. 交互示例</span></span></a></li></ul></li><li><a class="level is-mobile" href="#重要说明"><span class="level-left"><span class="level-item">2</span><span class="level-item">重要说明</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#🔑-核心设计特点"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">🔑 核心设计特点</span></span></a></li><li><a class="level is-mobile" href="#⚠️-注意事项"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">⚠️ 注意事项</span></span></a></li><li><a class="level is-mobile" href="#💡-扩展建议"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">💡 扩展建议</span></span></a></li></ul></li><li><a class="level is-mobile" href="#极简Transformer实现：完整设计文档说明（面向初学者）"><span class="level-left"><span class="level-item">3</span><span class="level-item">极简Transformer实现：完整设计文档说明（面向初学者）</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#一、项目目标与设计哲学"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">一、项目目标与设计哲学</span></span></a></li><li><a class="level is-mobile" href="#🎯-核心目标"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">🎯 核心目标</span></span></a></li><li><a class="level is-mobile" href="#二、整体架构设计"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">二、整体架构设计</span></span></a></li></ul><li><a class="level is-mobile" href="#🌐-系统架构图"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">🌐 系统架构图</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#三、核心组件详解（含实现逻辑）"><span class="level-left"><span class="level-item">3.2.1</span><span class="level-item">三、核心组件详解（含实现逻辑）</span></span></a></li><li><a class="level is-mobile" href="#为什么简化训练？"><span class="level-left"><span class="level-item">3.2.2</span><span class="level-item">为什么简化训练？</span></span></a></li><li><a class="level is-mobile" href="#设计选择"><span class="level-left"><span class="level-item">3.2.3</span><span class="level-item">设计选择</span></span></a></li><li><a class="level is-mobile" href="#四、训练与推理流程"><span class="level-left"><span class="level-item">3.2.4</span><span class="level-item">四、训练与推理流程</span></span></a></li><li><a class="level is-mobile" href="#五、效果评估与局限性"><span class="level-left"><span class="level-item">3.2.5</span><span class="level-item">五、效果评估与局限性</span></span></a></li><li><a class="level is-mobile" href="#六、学习路径建议（初学者）"><span class="level-left"><span class="level-item">3.2.6</span><span class="level-item">六、学习路径建议（初学者）</span></span></a></li><li><a class="level is-mobile" href="#七、完整代码结构（带注释索引）"><span class="level-left"><span class="level-item">3.2.7</span><span class="level-item">七、完整代码结构（带注释索引）</span></span></a></li><li><a class="level is-mobile" href="#八、常见问题解答（FAQ）"><span class="level-left"><span class="level-item">3.2.8</span><span class="level-item">八、常见问题解答（FAQ）</span></span></a></li><li><a class="level is-mobile" href="#总结：初学者收获清单"><span class="level-left"><span class="level-item">3.2.9</span><span class="level-item">总结：初学者收获清单</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list>li>a.is-active+.menu-list{display:block}#toc .menu-list>li>a+.menu-list{display:none}</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/9a6c398f.html"><img src="/assets/images/golang/golang-01.png" alt="【sort】深入解构Go标准库sort包设计原理以及实践开发中注意的要点"></a></figure><div class="media-content"><p class="date"><time datetime="2026-02-01T15:27:31.000Z">2026-02-01</time></p><p class="title"><a href="/9a6c398f.html">【sort】深入解构Go标准库sort包设计原理以及实践开发中注意的要点</a></p><p class="categories"><a href="/categories/golang/">golang</a> / <a href="/categories/golang/standard-library/">standard-library</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/d7d74826.html"><img src="/assets/images/golang/golang-01.png" alt="【os】深入解构Go标准库os包系统编程的基石以及实践开发中注意的要点"></a></figure><div class="media-content"><p class="date"><time datetime="2026-01-28T15:59:43.000Z">2026-01-28</time></p><p class="title"><a href="/d7d74826.html">【os】深入解构Go标准库os包系统编程的基石以及实践开发中注意的要点</a></p><p class="categories"><a href="/categories/golang/">golang</a> / <a href="/categories/golang/standard-library/">standard-library</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/a6cbebf9.html"><img src="/assets/images/golang/golang-01.png" alt="【time】深入解构Go标准库time包的设计原理以及开发中注意的要点"></a></figure><div class="media-content"><p class="date"><time datetime="2026-01-28T14:17:44.000Z">2026-01-28</time></p><p class="title"><a href="/a6cbebf9.html">【time】深入解构Go标准库time包的设计原理以及开发中注意的要点</a></p><p class="categories"><a href="/categories/golang/">golang</a> / <a href="/categories/golang/standard-library/">standard-library</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/916d238a.html"><img src="/assets/images/golang/golang-01.png" alt="【log】深入解构Go标准库log包设计原理以及实践开发中注意的要点"></a></figure><div class="media-content"><p class="date"><time datetime="2026-01-27T18:32:14.000Z">2026-01-28</time></p><p class="title"><a href="/916d238a.html">【log】深入解构Go标准库log包设计原理以及实践开发中注意的要点</a></p><p class="categories"><a href="/categories/golang/">golang</a> / <a href="/categories/golang/standard-library/">standard-library</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/996cf37b.html"><img src="/assets/images/golang/golang-01.png" alt="【fmt】深入解构Go标准库fmt从函数全景到内核原理以及开发中注意的要点"></a></figure><div class="media-content"><p class="date"><time datetime="2026-01-27T18:20:16.000Z">2026-01-28</time></p><p class="title"><a href="/996cf37b.html">【fmt】深入解构Go标准库fmt从函数全景到内核原理以及开发中注意的要点</a></p><p class="categories"><a href="/categories/golang/">golang</a> / <a href="/categories/golang/standard-library/">standard-library</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI/AIGC/"><span class="level-start"><span class="level-item">AIGC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/Agent/"><span class="level-start"><span class="level-item">Agent</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/Algo/"><span class="level-start"><span class="level-item">Algo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/AI/LLM/"><span class="level-start"><span class="level-item">LLM</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/GIT/"><span class="level-start"><span class="level-item">GIT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/architecture/"><span class="level-start"><span class="level-item">architecture</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/clang/"><span class="level-start"><span class="level-item">clang</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/cloud/"><span class="level-start"><span class="level-item">cloud</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/daily/"><span class="level-start"><span class="level-item">daily</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/daily/business/"><span class="level-start"><span class="level-item">business</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/daily/note/"><span class="level-start"><span class="level-item">note</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/golang/"><span class="level-start"><span class="level-item">golang</span></span><span class="level-end"><span class="level-item tag">45</span></span></a><ul><li><a class="level is-mobile" href="/categories/golang/standard-library/"><span class="level-start"><span class="level-item">standard-library</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/categories/golang/tutorial/"><span class="level-start"><span class="level-item">tutorial</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/java/"><span class="level-start"><span class="level-item">java</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/javascript/"><span class="level-start"><span class="level-item">javascript</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/linux/"><span class="level-start"><span class="level-item">linux</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/linux/centos/"><span class="level-start"><span class="level-item">centos</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/linux/debian/"><span class="level-start"><span class="level-item">debian</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/linux/security/"><span class="level-start"><span class="level-item">security</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/linux/tools/"><span class="level-start"><span class="level-item">tools</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/lua/"><span class="level-start"><span class="level-item">lua</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/macOS/"><span class="level-start"><span class="level-item">macOS</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/message/"><span class="level-start"><span class="level-item">message</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/nosql/"><span class="level-start"><span class="level-item">nosql</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/olap/"><span class="level-start"><span class="level-item">olap</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/php/"><span class="level-start"><span class="level-item">php</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/rdbms/"><span class="level-start"><span class="level-item">rdbms</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/rdbms/mysql/"><span class="level-start"><span class="level-item">mysql</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/rdbms/postgres/"><span class="level-start"><span class="level-item">postgres</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/rdbms/sql/"><span class="level-start"><span class="level-item">sql</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/reprinted-articles/"><span class="level-start"><span class="level-item">reprinted-articles</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/0to1/"><span class="tag">0to1</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI/"><span class="tag">AI</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AIGC/"><span class="tag">AIGC</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agent/"><span class="tag">Agent</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agent-Skill/"><span class="tag">Agent-Skill</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agent-Suggestion/"><span class="tag">Agent-Suggestion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agent-architecture/"><span class="tag">Agent-architecture</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Agent-framework/"><span class="tag">Agent-framework</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Algorithm/"><span class="tag">Algorithm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BP/"><span class="tag">BP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CDN/"><span class="tag">CDN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CentOS/"><span class="tag">CentOS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud-Distributed/"><span class="tag">Cloud-Distributed</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud-Native/"><span class="tag">Cloud-Native</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cloud-Native-Framework/"><span class="tag">Cloud-Native-Framework</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Controlnet/"><span class="tag">Controlnet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DDD/"><span class="tag">DDD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Debian/"><span class="tag">Debian</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DeepSeek/"><span class="tag">DeepSeek</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deepseek/"><span class="tag">Deepseek</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Demo-AI/"><span class="tag">Demo-AI</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Distributed-Systems/"><span class="tag">Distributed-Systems</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Drawing/"><span class="tag">Drawing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ES/"><span class="tag">ES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Economy/"><span class="tag">Economy</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eino/"><span class="tag">Eino</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Elastic/"><span class="tag">Elastic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ElasticSearch/"><span class="tag">ElasticSearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Firewalld/"><span class="tag">Firewalld</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Framework/"><span class="tag">Framework</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GGUF/"><span class="tag">GGUF</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GIT/"><span class="tag">GIT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GO-%E6%96%B9%E6%B3%95%E5%80%BC/"><span class="tag">GO 方法值</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPG/"><span class="tag">GPG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPG2/"><span class="tag">GPG2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GRPO/"><span class="tag">GRPO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GUI/"><span class="tag">GUI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ghostty/"><span class="tag">Ghostty</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag">46</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-Summary-notes/"><span class="tag">Go Summary notes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-null-judge/"><span class="tag">Go null judge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-Struct-Method-Receiver/"><span class="tag">Go(Struct|Method|Receiver)</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-map/"><span class="tag">Go(map)</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-new-make-struct/"><span class="tag">Go(new,make,struct{})</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-string/"><span class="tag">Go(string)</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-LLM/"><span class="tag">Go-LLM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-Polymorphism/"><span class="tag">Go-Polymorphism</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-Printf/"><span class="tag">Go-Printf</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-bytes/"><span class="tag">Go-bytes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-chain-operation/"><span class="tag">Go-chain-operation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-context/"><span class="tag">Go-context</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-errors/"><span class="tag">Go-errors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-fmt/"><span class="tag">Go-fmt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-init/"><span class="tag">Go-init()</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-io/"><span class="tag">Go-io</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-log/"><span class="tag">Go-log</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-math/"><span class="tag">Go-math</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-math-rand/"><span class="tag">Go-math-rand</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-net/"><span class="tag">Go-net</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-net-http/"><span class="tag">Go-net-http</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-os/"><span class="tag">Go-os</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-path/"><span class="tag">Go-path</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-sort/"><span class="tag">Go-sort</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-standard-library/"><span class="tag">Go-standard-library</span><span class="tag">18</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-sync/"><span class="tag">Go-sync</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go-time/"><span class="tag">Go-time</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Golang/"><span class="tag">Golang</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Google/"><span class="tag">Google</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HEART/"><span class="tag">HEART</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/History/"><span class="tag">History</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Infra/"><span class="tag">Infra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JS/"><span class="tag">JS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JSON/"><span class="tag">JSON</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java17/"><span class="tag">Java17</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java8/"><span class="tag">Java8</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaScript/"><span class="tag">JavaScript</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/K3S-Build/"><span class="tag">K3S-Build</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/K8S/"><span class="tag">K8S</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/K8S-Build/"><span class="tag">K8S-Build</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kafka/"><span class="tag">Kafka</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLM/"><span class="tag">LLM</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LoRA/"><span class="tag">LoRA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MCP/"><span class="tag">MCP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Message/"><span class="tag">Message</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Microservices/"><span class="tag">Microservices</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MongoDB/"><span class="tag">MongoDB</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Movie/"><span class="tag">Movie</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Note-The-Legend-of-1900/"><span class="tag">Note The Legend of 1900</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OLAP/"><span class="tag">OLAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenSSH/"><span class="tag">OpenSSH</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Qwen/"><span class="tag">Qwen</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RDBMS/"><span class="tag">RDBMS</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROI/"><span class="tag">ROI</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RabbitMQ/"><span class="tag">RabbitMQ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Rocky-linux/"><span class="tag">Rocky-linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SD/"><span class="tag">SD</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOP/"><span class="tag">SOP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Skill/"><span class="tag">Skill</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/StarRocks/"><span class="tag">StarRocks</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Syntax/"><span class="tag">Syntax</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TS/"><span class="tag">TS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Text2SQL/"><span class="tag">Text2SQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tutorial/"><span class="tag">Tutorial</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TypeScript/"><span class="tag">TypeScript</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UFW/"><span class="tag">UFW</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VIM/"><span class="tag">VIM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VIM-Author/"><span class="tag">VIM Author</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XHProf/"><span class="tag">XHProf</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ansi-lib/"><span class="tag">ansi-lib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/banner/"><span class="tag">banner</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/business/"><span class="tag">business</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/business-plan/"><span class="tag">business-plan</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/centos7/"><span class="tag">centos7</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/changelog/"><span class="tag">changelog</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/chattr/"><span class="tag">chattr</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/clang/"><span class="tag">clang</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cli/"><span class="tag">cli</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/daily/"><span class="tag">daily</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/database/"><span class="tag">database</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/debian/"><span class="tag">debian</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/firewalld/"><span class="tag">firewalld</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/format/"><span class="tag">format</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/func/"><span class="tag">func</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/go-pprof/"><span class="tag">go-pprof</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/goroutine/"><span class="tag">goroutine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/history/"><span class="tag">history</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/history-of-programing/"><span class="tag">history-of-programing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/homebrew/"><span class="tag">homebrew</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/innodb/"><span class="tag">innodb</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/interface/"><span class="tag">interface</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/io/"><span class="tag">io</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kebernetes/"><span class="tag">kebernetes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/laravel/"><span class="tag">laravel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/laravel-artisan/"><span class="tag">laravel-artisan</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/lua/"><span class="tag">lua</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/macOS/"><span class="tag">macOS</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/macro/"><span class="tag">macro</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/motd/"><span class="tag">motd</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql/"><span class="tag">mysql</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql8-0/"><span class="tag">mysql8.0</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mysql8-x/"><span class="tag">mysql8.x</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nanochat/"><span class="tag">nanochat</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nanochat-zh-CN/"><span class="tag">nanochat-zh_CN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/neofetch/"><span class="tag">neofetch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nginx/"><span class="tag">nginx</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nosql/"><span class="tag">nosql</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/oh-my-zsh/"><span class="tag">oh-my-zsh</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/omz/"><span class="tag">omz</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/openssl/"><span class="tag">openssl</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/package-time/"><span class="tag">package time</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/painting/"><span class="tag">painting</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/php/"><span class="tag">php</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pointer/"><span class="tag">pointer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgresql/"><span class="tag">postgresql</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgresql-syntax/"><span class="tag">postgresql-syntax</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/postgressql-engine/"><span class="tag">postgressql-engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reflect-%E5%8F%8D%E5%B0%84/"><span class="tag">reflect 反射</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rocky/"><span class="tag">rocky</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rocky-linux/"><span class="tag">rocky-linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rocky-linux-tools/"><span class="tag">rocky-linux-tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rsync/"><span class="tag">rsync</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rune/"><span class="tag">rune</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/security/"><span class="tag">security</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/services/"><span class="tag">services</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/slice-%E5%88%87%E7%89%87%E6%9C%AC%E8%B4%A8/"><span class="tag">slice 切片本质</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sql/"><span class="tag">sql</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/stable-diffusion-webui/"><span class="tag">stable-diffusion-webui</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/struct/"><span class="tag">struct</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/switch/"><span class="tag">switch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/systemd-service/"><span class="tag">systemd-service</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/terminal/"><span class="tag">terminal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/travel/"><span class="tag">travel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/type/"><span class="tag">type</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/type-%E5%85%B3%E9%94%AE%E8%AF%8D%E6%80%BB%E7%BB%93/"><span class="tag">type 关键词总结</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/utf8mb4/"><span class="tag">utf8mb4</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/utf8mb4-0900-ai-ci/"><span class="tag">utf8mb4_0900_ai_ci</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/utf8mb4-general-ci/"><span class="tag">utf8mb4_general_ci</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/zsh/"><span class="tag">zsh</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E7%94%9F/"><span class="tag">人生</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AE%89%E5%85%A8%E5%8A%A0%E5%9B%BA/"><span class="tag">安全加固</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%97%A5%E5%B8%B8/"><span class="tag">日常</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%B4%BB/"><span class="tag">生活</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AC%E8%BD%BD/"><span class="tag">转载</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BD%93%E7%B3%BB/"><span class="tag">配置文件体系</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%98%B2%E7%81%AB%E5%A2%99/"><span class="tag">防火墙</span><span class="tag">3</span></a></div></div></div></div></div><div class="card widget" data-type="clustrmaps"><div class="card-content"><div class="menu"><h3 class="menu-label">CLUSTRMAPS</h3></div><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div style="margin-top:10px"><script type="text/javascript" id="clustrmaps" src="https://cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=250&amp;t=n&amp;d=xb7wV_PHYtl9KaSZpQgP9CLUNrXlqm480vcarJmX2A0&amp;co=2d78ad&amp;cmo=3acc3a&amp;cmn=ff5353&amp;ct=ffffff"></script><script type="text/javascript" id="clstr_globe" src="https://clustrmaps.com/globe.js?d=xb7wV_PHYtl9KaSZpQgP9CLUNrXlqm480vcarJmX2A0"></script></div></div></nav></div></div><div class="card widget" data-type="adsense"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-8952360410310192" data-ad-slot="1345698037" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div></div></div></div></div></section><footer class="footer" style="padding:1rem 1.5rem 0"><div class="container"><div class="level"><div class="level-start"><p class="is-size-7"><a class="footer-logo" style="margin-right:10px" href="/"><img src="/img/logo.svg" alt="Jaco Liu Personal Site (ljq@GitHub).安全贯穿于软件开发各个环节." height="16" style="max-height:1.25rem"></a><a href="http://beian.miit.gov.cn" target="_blank">鲁ICP备2023051700号</a>  <span>&copy; 2026 Jaco Liu</span>  <span style="color:#e0e0e0">Powered by <a style="color:#e0e0e0" href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a style="color:#e0e0e0" href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></span><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>  <span id="busuanzi_container_site_pv">Total Visits Counts: <span id="busuanzi_value_site_pv"></span>.</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Jaco Liu&#039;GitHub" href="https://github.com/ljq"><i class="fab fa-github"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="ref.wdft.com" href="https://ref.wdft.com"><i class="fas fa-cloud"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="cook.wdft.com" href="https://cook.wdft.com"><i class="fas fa-coffee"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Python PEP8" href="https://pep8.org"><i class="fas fa-coffee"></i></a></p> <span><i class="fas fa-link">BlogRoll:</i></span><p class="control" style="color:#26c1fa"><a class="button is-transparent" target="_blank" rel="noopener" title="Quick Reference" href="https://ref.wdft.com">Quick Reference</a></p><p class="control" style="color:#26c1fa"><a class="button is-transparent" target="_blank" rel="noopener" title="Cook" href="https://cook.wdft.com">Cook</a></p><p class="control" style="color:#26c1fa"><a class="button is-transparent" target="_blank" rel="noopener" title="koala-oss.app" href="https://koala-oss.app/news/">koala-oss.app</a></p><p class="control" style="color:#26c1fa"><a class="button is-transparent" target="_blank" rel="noopener" title="CS自学指南" href="https://csdiy.wiki">CS自学指南</a></p><p class="control" style="color:#26c1fa"><a class="button is-transparent" target="_blank" rel="noopener" title="Python PEP8" href="https://pep8.org">Python PEP8</a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="/js/switchDarkMode.js" defer></script><script src="/js/toutiaoSEO.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load",()=>{window.cookieconsent.initialise({type:"info",theme:"edgeless",static:!1,position:"bottom-left",content:{message:"This website uses cookies to improve your experience.",dismiss:"Got it!",allow:"Allow cookies",deny:"Decline",link:"Learn more",policy:"Cookie Policy",href:"https://www.cookiesandyou.com/"},palette:{popup:{background:"#edeff5",text:"#838391"},button:{background:"#4b81e8"}}})})</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load",()=>{"function"==typeof $.fn.lightGallery&&$(".article").lightGallery({selector:".gallery-item"}),"function"==typeof $.fn.justifiedGallery&&($(".justified-gallery > p > .gallery-item").length&&$(".justified-gallery > p > .gallery-item").unwrap(),$(".justified-gallery").justifiedGallery())})</script><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",function(){loadInsight({contentUrl:"/content.json"},{hint:"Type something...",untitled:"(Untitled)",posts:"Posts",pages:"Pages",categories:"Categories",tags:"Tags"})})</script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7},"pluginJsPath":"lib/","pluginRootPath":"live2dw/"});</script></body></html>